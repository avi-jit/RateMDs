{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora.wikicorpus import WikiCorpus\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from pprint import pprint\n",
    "import multiprocessing\n",
    "import gensim\n",
    "print(gensim.__version__) # 0.12.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read grouped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df1 = pd.read_pickle('grouped.pickle')\n",
    "\n",
    "shuffle = True\n",
    "if shuffle == True:\n",
    "    df = df1.sample(frac=1)\n",
    "else:\n",
    "    df = df1\n",
    "\n",
    "R = df['text']\n",
    "G = df['gender']\n",
    "S = df['specialty']\n",
    "rating = df['scores']\n",
    "\n",
    "print(R[0][1],rating[0],type(rating[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R2 = []\n",
    "for i in range(len(R)):\n",
    "    R2.append(R.iloc[i])\n",
    "#print(R1[172])\n",
    "G2 = []\n",
    "for i in range(len(G)):\n",
    "    G2.append(G.iloc[i])\n",
    "print(G2[172])\n",
    "\n",
    "S2 = []\n",
    "for i in range(len(S)):\n",
    "    S2.append(S.iloc[i])\n",
    "print(S2[172])\n",
    "\n",
    "rating2 = []\n",
    "for i in range(len(rating)):\n",
    "    rating2.append(rating.iloc[i])\n",
    "print(rating2[172])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "x = rating2[13]\n",
    "y = ast.literal_eval(x)\n",
    "y[1]\n",
    "len(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores,scores2 = [],[] # scores is -1,0,1. scores2 is raw average score.\n",
    "for rr in rating2:\n",
    "    r = ast.literal_eval(rr)\n",
    "    score = 0\n",
    "    counts = 0 # no. of valid ratings present out of 4\n",
    "    for rr1 in r:\n",
    "        try:\n",
    "            r1 = int(ast.literal_eval(rr1))\n",
    "        except:\n",
    "            r1 = int(rr1)\n",
    "        #print(r1)\n",
    "        if(r1>0 and r1<=5):\n",
    "            score += r1\n",
    "            counts += 1\n",
    "    try:\n",
    "        score = score/counts\n",
    "        #if score > 4.6:\n",
    "        if score > 4:\n",
    "            final_score = '1'\n",
    "        #elif score < 3:\n",
    "        elif score < 3.5:\n",
    "            final_score = '-1'\n",
    "        else:\n",
    "            final_score = '0'\n",
    "    except:\n",
    "        final_score = '0'\n",
    "    scores.append(final_score)\n",
    "    scores2.append(score)\n",
    "    #print(score)\n",
    "len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_freq = {}\n",
    "for i in scores:\n",
    "    try:\n",
    "        scores_freq[i]+=1\n",
    "    except:\n",
    "        scores_freq[i]= 1\n",
    "scores_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R1,S1,G1,rating1 = [],[],[],[]\n",
    "for i,s in enumerate(S2):\n",
    "    if s == '-1':\n",
    "        continue\n",
    "    R1.append(R2[i])\n",
    "    S1.append(S2[i])\n",
    "    G1.append(G2[i])\n",
    "    rating1.append(scores[i])\n",
    "\n",
    "R1=R2\n",
    "S1=S2\n",
    "G1=G2\n",
    "rating1=scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Picker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [],
   "source": [
    "# create reverse dictionary. Scores-> index. Specialties -> index.\n",
    "revSpcl, revScore = {},{}\n",
    "revSS = {}\n",
    "for i in range(len(S1)):\n",
    "    spcl = S1[i]\n",
    "    score = rating1[i]\n",
    "    try:\n",
    "        revSpcl[spcl].append(i)\n",
    "    except:\n",
    "        revSpcl[spcl] = [i]\n",
    "    try:\n",
    "        revScore[score].append(i)\n",
    "    except:\n",
    "        revScore[score] = [i]\n",
    "    # JUST TO CHECK IF SOME PAIR IS TOO RARE.\n",
    "    try:\n",
    "        revSS[spcl+':'+score+':'+G1[i]]+= 1\n",
    "    except:\n",
    "        revSS[spcl+':'+score+':'+G1[i]] = 1\n",
    "#len(revScore['1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Throw a dice for specialty. Get the corresponding reverse dict. Take intersection. Find a male one,  a female one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def picker(roll_rating=False):\n",
    "    spcl = '-1'\n",
    "    while(spcl=='-1'): # Ignoring others.\n",
    "        spcl = random.choice(list(revSpcl.keys()))\n",
    "    spcl_cand = revSpcl[spcl]\n",
    "    score = random.choice(list(revScore.keys()))\n",
    "    score_cand = revScore[score]\n",
    "    cand = set(spcl_cand).intersection(set(score_cand))\n",
    "    #return list(cand)\n",
    "    #return score_cand\n",
    "    if roll_rating:\n",
    "        return list(cand)\n",
    "    else:\n",
    "        return list(spcl_cand) # now only one coin toss, that decides specialty. work better? family male -1 has just 11 reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "choice = random.choice(picker(roll_rating=True))\n",
    "print(choice, rating1[choice], S1[choice])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tag and Learn Embeddings (Online)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "docs = [] # each row is a tagged document.\n",
    "for i in range(len(R1)):\n",
    "    docs.append(gensim.models.doc2vec.TaggedDocument(R1[i], [S1[i],G1[i],rating1[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_for_vocab = [] # contains no -1. Not updating docs because then reverese lists must also be updated.\n",
    "for i in docs:\n",
    "    if i[1][0] == '-1':\n",
    "        continue\n",
    "    else:\n",
    "        docs_for_vocab.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeat = {}\n",
    "def online(model,batch_size=1,repeat=repeat,roll_rating=False):\n",
    "    indices = []\n",
    "    batch = []\n",
    "    #print('checkpoint3')\n",
    "    for b in range(batch_size):\n",
    "        pickm = False\n",
    "        pickf = False\n",
    "        cand = picker(roll_rating=roll_rating)\n",
    "        while(not pickm or not pickf):\n",
    "            choice = random.choice(cand)\n",
    "            if G2[choice]=='m':\n",
    "                if pickm:\n",
    "                    continue\n",
    "                else:\n",
    "                    pickm=True\n",
    "                    indices.append(choice)\n",
    "            else:\n",
    "                if pickf:\n",
    "                    continue\n",
    "                else:\n",
    "                    pickf=True\n",
    "                    indices.append(choice)\n",
    "    for i in indices: # only 2: one m, one f.\n",
    "        try:\n",
    "            repeat[i]+=1\n",
    "        except:\n",
    "            repeat[i]=1\n",
    "        #doc = gensim.models.doc2vec.TaggedDocument(R1[i], [S1[i],G1[i],rating1[i]])\n",
    "        batch.append(docs[i])\n",
    "    #print('checkpoint4')\n",
    "    model.train(batch, total_examples=model.corpus_count)\n",
    "    #print('checkpoint5')\n",
    "        #return model # not needed. it changes anyway."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparamter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import multiprocessing\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "\n",
    "cores = multiprocessing.cpu_count()\n",
    "size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_model(window,mc,sample,negative,batch_size,num_batches,roll_rating,index,iterations=1,hs=0,dm_concat=1,size=100):\n",
    "    model = Doc2Vec(dm=0,size=size,window=window,min_count=mc,sample=sample,iter=iterations,workers=cores,hs=hs,negative=negative,dbow_words=1,dm_concat=dm_concat)\n",
    "    #model = Doc2Vec(dm=1,size=size,window=window,min_count=mc,sample=sample,iter=iterations,workers=cores,hs=hs,negative=negative,dm_concat=dm_concat)\n",
    "    model.build_vocab(docs_for_vocab)\n",
    "    print(str(model))\n",
    "    model.intersect_word2vec_format('w2v.bin')\n",
    "    for i in range(1,num_batches):\n",
    "        online(model,batch_size=batch_size,roll_rating=roll_rating) # each batch has twice as many as these reviews. m,f.\n",
    "    version = str(i*batch_size*2)+'_'+str(model)\n",
    "    version = version[:-1]+',dm_concat'+str(dm_concat)+',rr'+str(roll_rating)+')'\n",
    "    #model.save('aug4/match_'+str(index)+'_'+version+'.model')\n",
    "    print(i,end='')\n",
    "    #print(\"model saved\")\n",
    "    #return str(model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "for hs in [0,1]: # 6912\n",
    "    for dm_concat in [0,1]: # 3456\n",
    "        for sample in [0,0.1,0.01,0.001]: # 1728\n",
    "            for roll_rating in [True,False]: # 432 almost done.\n",
    "                for window in [1,20,5,10,3,7]: # 216\n",
    "                    for min_count in [0,50,20,30,10,5]: #36\n",
    "                        for negative in [0,20,10,5,3,7]: # 6\n",
    "                            for num_batches in [20]:\n",
    "                                for batch_size in [10000]:\n",
    "                                    #print(index,end='')\n",
    "                                    m = one_model(window=window,mc=min_count,sample=sample,negative=negative,batch_size=batch_size,num_batches=num_batches,roll_rating=roll_rating,index=index,iterations=1,hs=hs,dm_concat=dm_concat,size=100)\n",
    "                                    index+=1\n",
    "                                    print(index)#,'\\t',info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.save('aug7_roll_rating_match_UNDEBIASED_noRating.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Words closest to 'm' and 'f' embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.most_similar(positive=[m.docvecs['m']])\n",
    "#m.most_similar(positive=[m.docvecs['f']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Words closest to specialty embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.most_similar(positive=[m.docvecs['gyn']])\n",
    "# and similarly for all individually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specialties closest to 'm' and 'f' embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.docvecs.most_similar(positive=[m.docvecs['m']])\n",
    "#m.docvecs.most_similar(positive=[m.docvecs['f']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positive adjectives for 'm' and 'f' embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.docvecs.most_similar(positive=[m.docvecs['m'],m.docvecs['1']],negative=[m.docvecs['f']])\n",
    "#m.docvecs.most_similar(positive=[m.docvecs['f'],m.docvecs['1']],negative=[m.docvecs['m']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# t-SNE plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "m = gensim.models.doc2vec.Doc2Vec.load('aug7_match_july21.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = set()\n",
    "for doc in m.docvecs.doctags:\n",
    "    print(doc)\n",
    "    for w in m.most_similar(positive=[m.docvecs[doc]],topn=5):\n",
    "        #print(w[0])\n",
    "        continue\n",
    "# list of class tags / docvecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Words to be plotted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#m.docvecs['1']\n",
    "words = set()\n",
    "for pair in m.most_similar(positive=[m.docvecs['m']],topn=5):\n",
    "    words.add(pair[0])\n",
    "for pair in m.most_similar(positive=[m.docvecs['f']],topn=5):\n",
    "    words.add(pair[0])\n",
    "    \n",
    "for doc in m.docvecs.doctags:\n",
    "    for pair in m.most_similar(positive=[m.docvecs[doc]],topn=5):\n",
    "        words.add(pair[0])\n",
    "    \n",
    "len(words)\n",
    "words = list(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def tsne_plot(model,words):\n",
    "    \"Creates and TSNE model and plots it\"\n",
    "    labels = []\n",
    "    tokens = []\n",
    "\n",
    "    for doc in model.docvecs.doctags:\n",
    "        tokens.append(model.docvecs[doc])\n",
    "        labels.append(\"#\"+doc+\"#\")\n",
    "    print(len(tokens),len(labels))\n",
    "    \n",
    "    ########## ADD NEW WORDS (specialty specific) ############\n",
    "    gn = []\n",
    "    gn.extend(['fertility','pregnancy','pregnant','delivery','egg','conceive','cycle','infertility','twin','baby'])\n",
    "    gn.extend(['skin','acne','face','plastic','scar','dermatologist'])\n",
    "    gn.extend(['disc','pt','fusion','knee','spine','shoulder','hip','lumbar','injury'])\n",
    "    gn.extend(['endocrinologist','thyroid','diabetes','blood','lab'])\n",
    "    gn.extend(['neurologist','spinal','brain','seizure','neurosurgeon','nerve'])\n",
    "    gn.extend(['kid','pediatrician','child','pediatric'])\n",
    "    gn.extend(['psychiatrist','mental','depression','therapist','illness'])\n",
    "    gn.extend(['eye','cataract','retina','vision','lens','glass','laser'])\n",
    "    gn.extend(['surgery','surgeon','cancer','tumor'])\n",
    "    gn.extend(['septum','sinus','nose','ear','hearing','throat','infection','allergy','breath','breathing'])\n",
    "    # also gender specific words\n",
    "    gn.extend(['he','his','him','man'])\n",
    "    gn.extend(['she','her','woman','herself'])\n",
    "    # also rating specific words\n",
    "    gn.extend(['great','good','excellent','caring','professional','wonderful','beautiful','caring'])\n",
    "    gn.extend(['worst','rude','not','horrible','well','however','doctor'])\n",
    "    \n",
    "    for w in gn:\n",
    "        try:\n",
    "            tokens.append(model[w])\n",
    "            labels.append(w)\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    print(len(tokens),len(labels))\n",
    "    print('now tsne-ing...')\n",
    "    \n",
    "    \n",
    "    tsne_model = TSNE(perplexity=40, n_components=2, init='pca', n_iter=2500, random_state=23)\n",
    "    new_values = tsne_model.fit_transform(tokens)\n",
    "\n",
    "    return new_values, labels\n",
    "    # RETURN CALLED.\n",
    "    \n",
    "    x = []\n",
    "    y = []\n",
    "    for value in new_values:\n",
    "        x.append(value[0])\n",
    "        y.append(value[1])\n",
    "        \n",
    "    plt.figure(figsize=(16, 16)) \n",
    "    for i in range(len(x)):\n",
    "        plt.scatter(x[i],y[i])\n",
    "        plt.annotate(labels[i],\n",
    "                     xy=(x[i], y[i]),\n",
    "                     xytext=(5, 2),\n",
    "                     textcoords='offset points',\n",
    "                     ha='right',\n",
    "                     va='bottom')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%time new_values,labels = tsne_plot(m,words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label and Colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = {}\n",
    "shape = {}\n",
    "alpha = {}\n",
    "color = {}\n",
    "\n",
    "for i in m.docvecs.doctags:\n",
    "    x = \"#\"+i+\"#\"\n",
    "    alpha[x] = 1.0\n",
    "    # remaining things below (in loop) are for specialties. specify differently for others.\n",
    "    size[x] = 15\n",
    "    shape[x] = 'x'\n",
    "    color[x] = 'g'\n",
    "    \n",
    "# gender:\n",
    "size[\"#f#\"] = 20\n",
    "shape[\"#f#\"] = (3,2,0)\n",
    "color[\"#f#\"] = 'r'\n",
    "\n",
    "size[\"#m#\"] = size[\"#f#\"]\n",
    "shape[\"#m#\"] = (3,2,180)\n",
    "color[\"#m#\"] = 'b'\n",
    "\n",
    "# rating:\n",
    "size[\"#1#\"] = 15\n",
    "shape[\"#1#\"] = (3,1,0)\n",
    "color[\"#1#\"] = 'y'\n",
    "\n",
    "size[\"#-1#\"] = size[\"#1#\"]\n",
    "shape[\"#-1#\"] = shape[\"#1#\"]\n",
    "color[\"#-1#\"] = color[\"#1#\"]\n",
    "\n",
    "size[\"#0#\"] = size[\"#-1#\"]\n",
    "shape[\"#0#\"] = shape[\"#-1#\"]\n",
    "color[\"#0#\"] = color[\"#-1#\"]\n",
    "\n",
    "# constant\n",
    "size[\"#constant#\"] = 15\n",
    "shape[\"#constant#\"] = '+'\n",
    "color[\"#constant#\"] = 'm'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "for value in new_values:\n",
    "    x.append(value[0])\n",
    "    y.append(value[1])\n",
    "\n",
    "plt.figure(figsize=(16, 16)) \n",
    "for i in range(len(x)):\n",
    "    try:\n",
    "        sz = size[labels[i]]\n",
    "        c = color[labels[i]]\n",
    "        sh = shape[labels[i]]\n",
    "        a = alpha[labels[i]]\n",
    "        print(sz,c,sh,a)\n",
    "    except:\n",
    "        # DEFAULT. i.e. WORDS.\n",
    "        sz = 10.0\n",
    "        c = 'k'\n",
    "        sh = 'o'\n",
    "        a = 0.9\n",
    "    plt.scatter(x[i],y[i],c=c,s=sz,marker=sh,alpha=a)\n",
    "    plt.annotate(labels[i],\n",
    "                 xy=(x[i], y[i]),\n",
    "                 xytext=(5, 2),\n",
    "                 textcoords='offset points',\n",
    "                 ha='right',\n",
    "                 va='bottom',color=c,fontsize=sz,alpha=a)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
